* Tasks

** TODO Refactor uri.html
   so the 3 tables are not repeated as hardcode
** TODO [#A] Handle timeouts
   Also: other reasons why HTTP request for URL might be broken
** DONE [#A] /page doesn't handle URIs with # in them
   Old idea was to use POST method instead of GET. But then i just replaced # with %23 in URLs, and now everything is working. Currently i don't see the point in using POST requests.

   Also, why Flask routing doesn't support #? It strips it from <path:uri>.
** TODO types of links for checking
   - http://launchpad.net/~sindikat
   - http://www.w3.org/1999/02/22-rdf-syntax-ns%23type (w3.org is out of reach; also has #)
   - http://www%23a - incorrect URL whatsoever
   - mailto:leigh@ldodds.com - shouldn't be allowed to put into address bar in the first place
** DONE [#A] Move from Graph to ConjunctiveGraph
** DONE [#A] Use persistence (Sleepycat)
** DONE [#A] When loading RDF from outer sources, put them in a Named Graph, instead of lumping them together
** TODO [#A] Only HTTP URIs should be dereferenced, not mailto: or tel:
   But maybe there should be a possibility to query KB for all mentions of the particular mailto:, tel: or a Literal
** TODO [#A] Go to the URL directly
   In addition to just dereferencing it inside my web-service
** TODO Manually add a triple (no Ajax at this point)
** TODO Try non-existent URL
   I tried http://localhost:17000/uri/http://ex.org/a#b. I got up with:

| As subject                   |                                                |
| Predicate                    | Object                                         |
| http://www.w3.org/ns/md#item | http://www.w3.org/1999/02/22-rdf-syntax-ns#nil |
** TODO Edit a triple
** TODO Delete a triple
** TODO Delete a named graph with all triples
** TODO Unify two named graphs
** TODO [#C] jQuery, Ajax, (possibly Backbone.js) - for in-place operation
** TODO Refactor dirty =result_to_xss= function
** TODO Manually create and populate named graphs
** TODO [#A] Maintain versions of named graphs
   specifically, put timestamp of last population from outer source
** TODO Gather data through RDFa
** TODO Gather data through SPARQL endpoints (maintain list of SPARQL endpoints?)
** TODO SPARQL endpoint
** TODO SPARUL endpoint
** TODO Use namespaces in the front-end
** TODO [#C] http://prefix.cc
** TODO [#C] List all URIs of the KB (do i need that?)
** TODO [#C] All subjects, all predicates, all objects
** TODO [#C] Move from rdflib to Virtuoso (or Sesame)
** TODO [#C] Use Virtuoso Sponger to crawl for data
** TODO [#C] Collapse "As subject", "As predicate", "As object"
** TODO [#C] Flash info about how URI was derefenced
   Flash additional info, for example if URI wasn't successfully dereferenced, print the error: maybe it was just HTML, maybe there was a parser error, maybe the URL is out of reach;
** TODO [#C] Exception logging
   For example, the HTTPError
** TODO [#C] Download module pyMicrodata
   for parsing Microdata
** TODO Possibly use requests library
   Instead of relying on "smart" Graph.parse(), which doesn't allow timeouts for example
